{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "models_validation.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chiaramarzi/ML-models-validation/blob/main/models_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTe8Jj3qhlw5"
      },
      "source": [
        "# Artificial intelligence (AI) for health - potentials\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGoOZvGALKgw"
      },
      "source": [
        "*   **Data mining**: finding pattern in big data\n",
        "*   **Biomarker discovery**: determining potential (compound) biomarkers\n",
        "*   The **predicitive nature** of machine learning strategies is highly in line with the aim of clinical diagnosis and prognosis **in the single patient**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUGpx9Z7iqL0"
      },
      "source": [
        "# Models validation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JwXyfF-LRej"
      },
      "source": [
        "In machine learning, model validation is referred to as the process where a trained model is evaluated with a testing data set. The testing data set is a separate portion of the same data set from which the training set is derived.\n",
        "Model validation is carried out after model training.\n",
        "\n",
        "Estimation of **unbiased generalization performance** of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ_Jo9T8SBbc"
      },
      "source": [
        "# Outline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9T0es-dSFsQ"
      },
      "source": [
        "* Holdout validation\n",
        "* K-fold cross-validation (CV)\n",
        "* Leave-One-Out CV (LOOCV)\n",
        "* Hyperparameters tuning\n",
        "* Training, validation and test set: the holdout validation\n",
        "* Training, validation and test set: the nested CV\n",
        "* Sampling bias\n",
        "* Repetition of holdout validation\n",
        "* Repetition of CV\n",
        "* Unbalanced datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfjOSjyakq9H"
      },
      "source": [
        "# Age prediction based on neuroimaging features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTl_nz8OLv_C"
      },
      "source": [
        "\n",
        "\n",
        "*   Data: T1-weighted images of 86 healthy subjects with age ranging from 19 to 85 years (41 males and 45 females, age 44.2 ± 17.1 years, mean ± standard deviation). Data are freely accessible at [here](https://fcon_1000.projects.nitrc.org/) and described in (Mazziotta et al., 2001)\n",
        "*   Features:\n",
        "  * Cortical thickness (mCT)\n",
        "  * Gyrification index (Pial_mean_GI)\n",
        "  * Fractal dimension (FD)\n",
        "* Task:\n",
        "  * Regression\n",
        "  * Classification (\"young\" vs. \"old\")\n",
        "\n",
        "The same data and features have been previously investigated in (Marzi et al., 2020).\n",
        "\n",
        "\n",
        "**References**\n",
        "\n",
        "Marzi, C., Giannelli, M., Tessa, C. et al. Toward a more reliable characterization of fractal properties of the cerebral cortex of healthy subjects during the lifespan. Sci Rep 10, 16957 (2020). https://doi.org/10.1038/s41598-020-73961-w\n",
        "\n",
        "Mazziotta, J. et al. A probabilistic atlas and reference system for the human brain: International Consortium for Brain Mapping (ICBM). Philos. Trans. R. Soc. Lond. B Biol. Sci. 356, 1293–1322. https://doi.org/10.1098/rstb.2001.0915 (2001)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im3BWk_5OVtS"
      },
      "source": [
        "# Libraries and data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MZY9faAOjaj",
        "outputId": "1d2225b9-b8d5-40dc-d539-86a09b13a12e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# My repo cloning\n",
        "! git clone https://github.com/chiaramarzi/ML-models-validation\n",
        "\n",
        "%cd /content/ML-models-validation\n",
        "! git pull"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ML-models-validation' already exists and is not an empty directory.\n",
            "/content/ML-models-validation\n",
            "\n",
            "*** Please tell me who you are.\n",
            "\n",
            "Run\n",
            "\n",
            "  git config --global user.email \"you@example.com\"\n",
            "  git config --global user.name \"Your Name\"\n",
            "\n",
            "to set your account's default identity.\n",
            "Omit --global to set the identity only in this repository.\n",
            "\n",
            "fatal: unable to auto-detect email address (got 'root@2f3f4197a81a.(none)')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vmE6GnKUpQ7"
      },
      "source": [
        "# Libraries loading\n",
        "from IPython.display import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_validate\n",
        "from sklearn.svm import SVR, SVC\n",
        "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
        "\n",
        "%run utils.ipynb import *\n",
        "\n",
        "# Regression data\n",
        "reg_data = pd.read_csv('data_regression.csv')\n",
        "\n",
        "# Balanced classification data\n",
        "class_data = pd.read_csv('data_classification_balanced.csv')\n",
        "\n",
        "# Unbalanced classification data\n",
        "unbal_class_data = pd.read_csv('data_classification_unbalanced.csv')"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSE0z7esU8Ky"
      },
      "source": [
        "reg_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndM8efnpVGAP"
      },
      "source": [
        "class_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YHx6EyaVHwK"
      },
      "source": [
        "unbal_class_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6G4jorBVPOI"
      },
      "source": [
        "# Holdout validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZRcU-8ZtQ0h"
      },
      "source": [
        "The principle is simple, you simply split your data randomly into roughly 70% used for training the model and 30% for testing the model. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moD3nhOSY0az"
      },
      "source": [
        "![](https://raw.githubusercontent.com/chiaramarzi/ML-models-validation/main/figures/IMG_4103.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z4UNX79uxKr"
      },
      "source": [
        "Image('figures/IMG_4103.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ftXYNS7hM81"
      },
      "source": [
        "#SEED = 42 #563: good, 0: perfect, 42: worse\n",
        "\n",
        "### REGRESSION ###\n",
        "print('***Regression task')\n",
        "\n",
        "X = reg_data.iloc[:,2:5]\n",
        "y = reg_data['Age']\n",
        "\n",
        "print('The whole dataset contains ' + str(np.shape(reg_data)[0]) + ' subjects')\n",
        "print('The age prediction will be performed using ' + str(np.shape(X)[1]) + ' MRI-derived features')\n",
        "print() \n",
        "\n",
        "regression_holdout(X, y, seed = 43, test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8J2_qJfzk-xl"
      },
      "source": [
        "### CLASSIFICATION ###\n",
        "print('***Classification task')\n",
        "\n",
        "X = class_data.iloc[:,2:5]\n",
        "y = class_data['Age_class']\n",
        "\n",
        "print('The whole dataset contains ' + str(np.shape(class_data)[0]) + ' subjects')\n",
        "print('The age prediction will be performed using ' + str(np.shape(X)[1]) + ' MRI-derived features')\n",
        "print() \n",
        "\n",
        "classification_holdout(X, y, seed = 43, stratify = None, test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBrm5c1DlgTV"
      },
      "source": [
        "# K-fold cross-validation (CV)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DJkmJ3alik5"
      },
      "source": [
        "It splits the data into k folds, then trains the data on k-1 folds and test on the one fold that was left out. It does this for all combinations and averages the result on each instance.\n",
        "\n",
        "The advantage is that all observations are used for both training and validation, and each observation is used once for validation. \n",
        "\n",
        "We typically choose either k=5 or k=10 as they find a nice balance between computational complexity and validation accuracy.\n",
        "\n",
        "The scores of each fold from CV techniques are more insightful than one may think. They are mostly used to simply extract the average performance. However, one might also look at the variance or standard deviation of the resulting folds as it will give information about the stability of the model across different data inputs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHpBE5XxmCpJ"
      },
      "source": [
        "### REGRESSION ###\n",
        "n_folds = 5 # for LOOCV insert n_fold = 86\n",
        "\n",
        "print('***Regression task')\n",
        "\n",
        "X = reg_data.iloc[:,2:5]\n",
        "y = reg_data['Age']\n",
        "\n",
        "print('The whole dataset contains ' + str(np.shape(reg_data)[0]) + ' subjects')\n",
        "print('The age prediction will be performed using ' + str(np.shape(X)[1]) + ' MRI-derived features')\n",
        "print() \n",
        "\n",
        "MAE_train, MAE_test = regression_CV(X, y, seed = 42, n_folds = n_folds)\n",
        "print_to_std(MAE_train, MAE_test, \"MAE\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ2aP-OsmhDK"
      },
      "source": [
        "### CLASSIFICATION ###\n",
        "n_folds = 5 # for LOOCV insert n_fold = 50\n",
        "\n",
        "print('***Classification task')\n",
        "\n",
        "X = class_data.iloc[:,2:5]\n",
        "y = class_data['Age_class']\n",
        "\n",
        "print('The whole dataset contains ' + str(np.shape(class_data)[0]) + ' subjects')\n",
        "print('The age prediction will be performed using ' + str(np.shape(X)[1]) + ' MRI-derived features')\n",
        "print() \n",
        "\n",
        "ACC_train, ACC_test = classification_CV(X, y, seed = 42, n_folds = n_folds)\n",
        "print_to_std(ACC_train, ACC_test, \"ACC\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XT91xJqm3in"
      },
      "source": [
        "  # Leave-one-out CV (LOOCV)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sgu3uRNBm-Jf"
      },
      "source": [
        "A variant of k-Fold CV is Leave-one-out Cross-Validation (LOOCV). \n",
        "\n",
        "LOOCV uses each sample in the data as a separate test set while all remaining samples form the training set. This variant is identical to k-fold CV when k = n (number of observations).\n",
        "\n",
        "LOOCV is computationally very costly as the model needs to be trained n times. Only do this if the dataset is small or if you can handle that many computations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuoxXbBGnPi0"
      },
      "source": [
        "### REGRESSION ###\n",
        "n_folds = 86\n",
        "\n",
        "print('***Regression task')\n",
        "\n",
        "X = reg_data.iloc[:,2:5]\n",
        "y = reg_data['Age']\n",
        "\n",
        "print('The whole dataset contains ' + str(np.shape(reg_data)[0]) + ' subjects')\n",
        "print('The age prediction will be performed using ' + str(np.shape(X)[1]) + ' MRI-derived features')\n",
        "print() \n",
        "\n",
        "MAE_train, MAE_test = regression_CV(X, y, seed = 42, n_folds = n_folds)\n",
        "print_to_std(MAE_train, MAE_test, \"MAE\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBzy85wWncCP"
      },
      "source": [
        "### CLASSIFICATION ###\n",
        "n_folds = 50\n",
        "\n",
        "print('***Classification task')\n",
        "\n",
        "X = class_data.iloc[:,2:5]\n",
        "y = class_data['Age_class']\n",
        "\n",
        "print('The whole dataset contains ' + str(np.shape(class_data)[0]) + ' subjects')\n",
        "print('The age prediction will be performed using ' + str(np.shape(X)[1]) + ' MRI-derived features')\n",
        "print() \n",
        "\n",
        "ACC_train, ACC_test = classification_CV(X, y, seed = 42, n_folds = n_folds)\n",
        "print_to_std(ACC_train, ACC_test, \"ACC\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-0dPq40nlXl"
      },
      "source": [
        "# Hyperparameters tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xN-9qQFnvl_"
      },
      "source": [
        "SVR()\n",
        "\n",
        "SVC()\n",
        "\n",
        "The c parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtagDWcOn6ur"
      },
      "source": [
        "# Training, validation and test set: the holdout validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y1riVe2oLTV"
      },
      "source": [
        "When optimizing the hyperparameters of your model, you might overfityour model if you were to optimize using the train/test split.\n",
        "Why? Because the model searches for the hyperparameters that fit the specific train/test you made.\n",
        "\n",
        "To solve this issue, you can create an additional holdout set. This is often 10% of the data which you have not used in any of your processing/validation steps.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLqXCvQhoVFP"
      },
      "source": [
        "SEED = 42 #563: good, 0: perfect, 42: worse\n",
        "\n",
        "### REGRESSION ###\n",
        "print('***Regression task')\n",
        "\n",
        "X = reg_data.iloc[:,2:5]\n",
        "y = reg_data['Age']\n",
        "\n",
        "print('The whole dataset contains ' + str(np.shape(reg_data)[0]) + ' subjects')\n",
        "print('The age prediction will be performed using ' + str(np.shape(X)[1]) + ' MRI-derived features')\n",
        "print() \n",
        "\n",
        "regression_holdout_val_set(X, y, SEED, test_set_size = 0.25, val_set_size = 0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHnjLjXLqI1-"
      },
      "source": [
        "### CLASSIFICATION ###\n",
        "print('***Classification task')\n",
        "\n",
        "X = class_data.iloc[:,2:5]\n",
        "y = class_data['Age_class']\n",
        "\n",
        "print('The whole dataset contains ' + str(np.shape(class_data)[0]) + ' subjects')\n",
        "print('The age prediction will be performed using ' + str(np.shape(X)[1]) + ' MRI-derived features')\n",
        "print() \n",
        "\n",
        "classification_holdout_val_set(X, y, SEED, test_set_size = 0.25, val_set_size = 0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzqJx2cMqalD"
      },
      "source": [
        "# Training, validation and test set: the nested CV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaADFev8rolQ"
      },
      "source": [
        "When you are optimizing the hyperparameters of your model and you use the same k-Fold CV strategy to tune the model and evaluate performance you run the risk of overfitting. You do not want to estimate the accuracy of your model on the same split that you found the best hyperparameters for.\n",
        "\n",
        "\n",
        "Instead, we use a Nested Cross-Validation strategy allowing to separate the hyperparameter tuning step from the error estimation step. To do this, we nest two k-fold cross-validation loops:\n",
        "\n",
        "\n",
        "*   The inner loop for hyperparameter tuning and\n",
        "*   the outer loop for estimating accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-U58KpmsGlN",
        "outputId": "14b7e655-da8a-44d0-c3ca-5a1d92cf2491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "source": [
        "SEED = 42\n",
        "\n",
        "### REGRESSION ###\n",
        "n_folds = 5\n",
        "\n",
        "print('***Regression task')\n",
        "\n",
        "X = reg_data.iloc[:,2:5]\n",
        "y = reg_data['Age']\n",
        "\n",
        "print('The whole dataset contains ' + str(np.shape(reg_data)[0]) + ' subjects')\n",
        "print('The age prediction will be performed using ' + str(np.shape(X)[1]) + ' MRI-derived features')\n",
        "print() \n",
        "\n",
        "MAE_tr_val, MAE_test = regression_nestedCV(X, y, SEED, n_folds)\n",
        "print_to_std(MAE_tr_val, MAE_test, \"MAE\")\n",
        "\n",
        "# NestedCV implemented in scikit-learn\n",
        "outer_cv = KFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
        "inner_cv = KFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
        "\n",
        "clf = SVR(kernel='rbf', degree=3, gamma='scale', coef0=0.0, tol=0.001, C=0.1, epsilon=0.1, shrinking=True, cache_size=200, verbose=1000, max_iter=- 1)\n",
        "p_grid = [{'C': [0.1, 1, 100]}]     \n",
        "      \n",
        "clf_gs = GridSearchCV(clf, param_grid=p_grid, cv=inner_cv, refit='neg_mean_absolute_error', scoring='neg_mean_absolute_error', n_jobs=1, verbose = 1000)\n",
        "nested_score = cross_validate(clf_gs, X=X, y=y, cv=outer_cv, return_train_score=True, return_estimator=True, scoring = 'neg_mean_absolute_error', n_jobs=1)\n",
        "###########################################################"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***Regression task\n",
            "The whole dataset contains 86 subjects\n",
            "The age prediction will be performed using 3 MRI-derived features\n",
            "\n",
            "*** Outer iteration: 1\n",
            "* Inner iteration: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-5c7832412d3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mMAE_tr_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAE_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregression_nestedCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSEED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint_to_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAE_tr_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAE_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MAE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-83-30e3391657b2>\u001b[0m in \u001b[0;36mregression_nestedCV\u001b[0;34m(X, y, seed, n_folds)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mMAE_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAE_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0mInner_iteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"c: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" with MAE: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mMAE_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m                 \u001b[0;31m#print(\"MAE\", MAE_v)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mMAE_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAE_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"float\") to str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA-GopPOsmo4"
      },
      "source": [
        "### CLASSIFICATION ###\n",
        "n_folds = 5\n",
        "\n",
        "print('***Classification task')\n",
        "\n",
        "X = class_data.iloc[:,2:5]\n",
        "y = class_data['Age_class']\n",
        "\n",
        "print('The whole dataset contains ' + str(np.shape(class_data)[0]) + ' subjects')\n",
        "print('The age prediction will be performed using ' + str(np.shape(X)[1]) + ' MRI-derived features')\n",
        "print() \n",
        "\n",
        "ACC_train, ACC_test = classification_nestedCV(X, y, SEED, n_folds)\n",
        "print_to_std(ACC_train, ACC_test, \"ACC\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEm4D3AVs1hX"
      },
      "source": [
        "# Sampling bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugdUBZ_Ys-A4"
      },
      "source": [
        "However, what if one subset of our data only have people of a certain age or income levels? This is typically referred to as a sampling bias. \n",
        "\n",
        "Sampling bias is systematic error due to a non-random sample of a population, causing some members of the population to be less likely to be included than others, resulting in a biased sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T1cTdbQtITQ"
      },
      "source": [
        "# Repetition of holdout validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATIUK0JItLdc"
      },
      "source": [
        "print('#### HOLDOUT REPETITION')\n",
        "\n",
        "### REGRESSION ###\n",
        "print('***Regression task')\n",
        "\n",
        "X = reg_data.iloc[:,2:5]\n",
        "y = reg_data['Age']\n",
        "\n",
        "print('The whole dataset contains ' + str(np.shape(reg_data)[0]) + ' subjects')\n",
        "print('The age prediction will be performed using ' + str(np.shape(X)[1]) + ' MRI-derived features')\n",
        "print() \n",
        "\n",
        "for SEED in range(0,10):\n",
        "    regression_holdout(X, y, seed = SEED, test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re_UEY8xte1a"
      },
      "source": [
        "### CLASSIFICATION ###\n",
        "print('***Classification task')\n",
        "\n",
        "X = class_data.iloc[:,2:5]\n",
        "y = class_data['Age_class']\n",
        "\n",
        "print('The whole dataset contains ' + str(np.shape(class_data)[0]) + ' subjects')\n",
        "print('The age prediction will be performed using ' + str(np.shape(X)[1]) + ' MRI-derived features')\n",
        "print() \n",
        "\n",
        "for SEED in range(0,10):\n",
        "    classification_holdout(X, y, SEED, test_size = 0.25, stratify = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDKhgOEptvRx"
      },
      "source": [
        "# Repetition of CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd9vC_WFtw_6"
      },
      "source": [
        "#### SAMPLING BIAS: HOLDOUT REPETITION ###\n",
        "print('#### HOLDOUT REPETITION')\n",
        "\n",
        "### REGRESSION ###\n",
        "n_folds = 5\n",
        "\n",
        "print('***Regression task')\n",
        "\n",
        "X = reg_data.iloc[:,2:5]\n",
        "y = reg_data['Age']\n",
        "\n",
        "print('The whole dataset contains ' + str(np.shape(reg_data)[0]) + ' subjects')\n",
        "print('The age prediction will be performed using ' + str(np.shape(X)[1]) + ' MRI-derived features')\n",
        "print() \n",
        "\n",
        "for SEED in range(1,10):\n",
        "    MAE_train, MAE_test = regression_CV(X, y, SEED, n_folds)\n",
        "    print_to_std(MAE_train, MAE_test, \"MAE\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byN32Bd6uCZo"
      },
      "source": [
        "### CLASSIFICATION ###\n",
        "n_folds = 5 \n",
        "\n",
        "print('***Classification task')\n",
        "\n",
        "X = class_data.iloc[:,2:5]\n",
        "y = class_data['Age_class']\n",
        "\n",
        "print('The whole dataset contains ' + str(np.shape(class_data)[0]) + ' subjects')\n",
        "print('The age prediction will be performed using ' + str(np.shape(X)[1]) + ' MRI-derived features')\n",
        "print() \n",
        "\n",
        "for SEED in range(1,10):\n",
        "    ACC_train, ACC_test = classification_CV(X, y, SEED, n_folds)\n",
        "    print_to_std(ACC_train, ACC_test, \"ACC\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQOYF10-uSR8"
      },
      "source": [
        "# Unbalanced datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlVF4wxeuX94"
      },
      "source": [
        "In some cases, there may be a large imbalance in the response variables. \n",
        "\n",
        "For example, in dataset concerning price of houses, there might be large number of houses having high price. Or in case of classification, there might be several times more negative samples than positive samples. For such problems, a slight variation in the K Fold cross validation technique is made, such that each fold contains approximately the same percentage of samples of each target class as the complete set, or in case of prediction problems, the mean response value is approximately equal in all the folds. \n",
        "\n",
        "This variation is also known as Stratified K Fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAITJP9Wuj2Z"
      },
      "source": [
        "SEED = 88\n",
        "#### UNBALANCED DATASETS ###\n",
        "print('#### UNBALANCED DATASETS')\n",
        "### CLASSIFICATION ###\n",
        "print('***Classification task')\n",
        "\n",
        "X = unbal_class_data.iloc[:,2:5]\n",
        "y = unbal_class_data['Age_class']\n",
        "\n",
        "print('The whole dataset contains ' + str(np.shape(unbal_class_data)[0]) + ' subjects')\n",
        "print('The age prediction will be performed using ' + str(np.shape(X)[1]) + ' MRI-derived features')\n",
        "print() \n",
        "\n",
        "'''\n",
        "for SEED in range(0,100):\n",
        "    print(\"SEED:\", SEED)\n",
        "    classification_holdout(X, y, SEED, stratify = None)\n",
        "    classification_holdout(X, y, SEED, stratify = y)\n",
        "\n",
        "'''\n",
        "\n",
        "classification_holdout(X, y, SEED, test_size = 0.25, stratify = None)\n",
        "classification_holdout(X, y, SEED, test_size = 0.25, stratify = y)\n",
        "\n",
        "# SEED = 95, 91, 88"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}